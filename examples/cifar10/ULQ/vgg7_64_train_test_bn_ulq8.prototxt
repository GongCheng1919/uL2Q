name: "CIFAR10_full"
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mean_file: "examples/cifar10/mean.binaryproto"
	scale:0.00390625
	mirror:1
  }
  data_param {
    source: "examples/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
  #activations_compress:"Quantize"
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "examples/cifar10/mean.binaryproto"
	scale:0.00390625
  }
  data_param {
    source: "examples/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
  ##activations_compress:"Quantize"
}
#conv1:3*3*64
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
	decay_mult:2
  }
  param {
    lr_mult: 2
  }
  weights_compress:"ULQ"
  weights_compress_param{
    maxbits:8
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
    bottom: "conv1_1"
    top: "conv1_1"
    name: "bn1_1"
    type: "BatchNorm"
	param {  
    lr_mult: 0  
    decay_mult: 0  
  }   
  param {  
    lr_mult: 0  
    decay_mult: 0  
  }  
  param {  
    lr_mult: 0  
    decay_mult: 0  
  }
  batch_norm_param {
		use_global_stats: false
  }
}
layer {  
  name: "scale1_1"  
  type: "Scale"
  bottom: "conv1_1"  
  top: "conv1_1"    
  scale_param {  
    bias_term: true  
  }
}

layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}

layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
	decay_mult:2
  }
  param {
    lr_mult: 2
  }
   weights_compress:"ULQ"
  weights_compress_param{
    maxbits:8
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}

layer {
    bottom: "conv1_2"
    top: "conv1_2"
    name: "bn1_2"
    type: "BatchNorm"
	param {  
    lr_mult: 0  
    decay_mult: 0  
  }   
  param {  
    lr_mult: 0  
    decay_mult: 0  
  }  
  param {  
    lr_mult: 0  
    decay_mult: 0  
  }
  batch_norm_param {
		use_global_stats: false
  }
}
layer {  
  name: "scale1_2"  
  type: "Scale"
  bottom: "conv1_2"  
  top: "conv1_2"    
  scale_param {  
    bias_term: true  
  }  
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
#conv2:3*3*128
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
	decay_mult:2
  }
  param {
    lr_mult: 2
  }
  weights_compress:"ULQ"
  weights_compress_param{
    maxbits:8
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
    bottom: "conv2_1"
    top: "conv2_1"
    name: "bn2_1"
    type: "BatchNorm"
	param {  
    lr_mult: 0  
    decay_mult: 0  
  }   
  param {  
    lr_mult: 0  
    decay_mult: 0  
  }  
  param {  
    lr_mult: 0  
    decay_mult: 0  
  }
  batch_norm_param {
		use_global_stats: false
  }
}
layer {  
  name: "scale2_1"  
  type: "Scale"
  bottom: "conv2_1"  
  top: "conv2_1"    
  scale_param {  
    bias_term: true  
  }  
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
	decay_mult:2
  }
  param {
    lr_mult: 2
  }
  weights_compress:"ULQ"
  weights_compress_param{
    maxbits:8
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
    bottom: "conv2_2"
    top: "conv2_2"
    name: "bn2_2"
    type: "BatchNorm"
	param {  
    lr_mult: 0  
    decay_mult: 0  
  }   
  param {  
    lr_mult: 0  
    decay_mult: 0  
  }  
  param {  
    lr_mult: 0  
    decay_mult: 0  
  }
  batch_norm_param {
		use_global_stats: false
  }
}
layer {  
  name: "scale2_2"  
  type: "Scale"
  bottom: "conv2_2"  
  top: "conv2_2"    
  scale_param {  
    bias_term: true  
  }  
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
#conv3:
#conv3_1:3*3*256
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
	decay_mult:2
  }
  param {
    lr_mult: 2
  }
  weights_compress:"ULQ"
  weights_compress_param{
    maxbits:8
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
    bottom: "conv3_1"
    top: "conv3_1"
    name: "bn3_1"
    type: "BatchNorm"
	param {  
    lr_mult: 0  
    decay_mult: 0  
  }   
  param {  
    lr_mult: 0  
    decay_mult: 0  
  }  
  param {  
    lr_mult: 0  
    decay_mult: 0  
  }
  batch_norm_param {
		use_global_stats: false
  }
}
layer {  
  name: "scale3_1"  
  type: "Scale"
  bottom: "conv3_1"  
  top: "conv3_1"    
  scale_param {  
    bias_term: true  
  }  
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
#conv3_2:3*3*256
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
	decay_mult:2
  }
  param {
    lr_mult: 2
  }
  weights_compress:"ULQ"
  weights_compress_param{
    maxbits:8
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
    bottom: "conv3_2"
    top: "conv3_2"
    name: "bn3_2"
    type: "BatchNorm"
	param {  
    lr_mult: 0  
    decay_mult: 0  
  }   
  param {  
    lr_mult: 0  
    decay_mult: 0  
  }  
  param {  
    lr_mult: 0  
    decay_mult: 0  
  }
  batch_norm_param {
		use_global_stats: false
  }
}
layer {  
  name: "scale3_2"  
  type: "Scale"
  bottom: "conv3_2"  
  top: "conv3_2"    
  scale_param {  
    bias_term: true  
  }  
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_2"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}

layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool3"
  top: "ip1"
  param {
    lr_mult: 1
	decay_mult:40
  }
  param {
    lr_mult: 2
  }
  weights_compress:"ULQ"
  weights_compress_param{
    maxbits:8
  }
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "dropout"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param{
	  dropout_ratio:0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
	decay_mult:40
  }
  param {
    lr_mult: 2
  }
  weights_compress:"ULQ"
  weights_compress_param{
    maxbits:8
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}

layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip2"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy_5"
  type: "Accuracy"
  bottom: "ip2"
  bottom: "label"
  top: "accuracy_5"
  accuracy_param
  {
    top_k:5
  }
  include {
    phase: TEST
  }
}



